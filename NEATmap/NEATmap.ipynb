{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEATmap Tutorial\n",
    "\n",
    "This [notebook](NEATmap.ipynb) is a tutorial to run the main processing script that qunatfies immediate early gene expression from lightsheet data of VISoR ceared brains"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The source for this notebook can be found here: \n",
    "<a class=\"reference download internal\" download=\"\" href=\"VISoRMap.ipynb\">\n",
    "    <code class=\"xref download docutils literal notranslate\"><span class=\"pre\">VISoRMap.ipynb</span></code></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__    = 'Weijie Zheng <wjzheng.ahu@gmail.com>'\n",
    "__license__   = 'GPLv3 - GNU General Pulic License v3'\n",
    "__copyright__ = 'Copyright © 2023 by Weijie Zheng'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize NEATmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VISoRMap path\n",
    "import sys\n",
    "sys.path.append(r'R:\\WeijieZheng\\VISoRMap_Code\\VISoRMap')\n",
    "#load VISoRMap modules and parameters\n",
    "from Environment import *\n",
    "from Parameter import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing\n",
    "### Volume images\n",
    "VISoR reconstruction of the generated BrainImage path with 561nm channels and 488nm channels to synthesize 3D images with (z, x, y) size (64,3500,2500)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 561 channel\n",
    "root = Data_root\n",
    "save_brain3d_path = os.path.join(Data_root, 'brain_image_64_' + Channels['staining'])\n",
    "json_path = os.path.join(Raw_data_root, '..', 'freesia_4.0_C2_488nm_10X.json')\n",
    "with open(json_path) as f:\n",
    "    brain = json.load(f)\n",
    "    images = brain['images']\n",
    "    total_num = len(images)\n",
    "b2t3.brain2dto3d(Raw_data_root, save_brain3d_path, total_num, z_num=Preprocessing['z_num'], channel_index=Channels['561nm_index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 488 channel\n",
    "save_brain3d_path = os.path.join(Data_root, 'brain_image_64_' + Channels['autofluo'])\n",
    "b2t3.brain2dto3d(Raw_data_root, save_brain3d_path, total_num, z_num=Preprocessing['z_num'], channel_index=Channels['488nm_index'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output is a volumetric image of the labeled signal channel and the autofluorescence channel. For input into the neural network, we set the thickness to 256 µm.\n",
    "If the thickness value is changed, modify the parameter `Preprocessing['z_num']`.\n",
    "* `Raw_data_root` is the path to get the data after reconstruction.\n",
    "* `Data_root` is the path to the workspace.\n",
    "* `channel_index` is the channel index corresponding to the labeled signal channel and the autofluorescence channel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image clipping\n",
    "Synthetic 3d brain slices were clip into 70 patches. If you get the training data, you need to input the parameters train_path and label_path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cut 561nm channel\n",
    "cut.cut(root=Data_root, cut_size=Preprocessing['cut_size'], channel=Channels['staining'],\n",
    "cut_index_x=Preprocessing['cut_index_x'], cut_index_y=Preprocessing['cut_index_y'], \n",
    "patch_weight_num=Preprocessing['patch_weight_num'], patch_hegiht_num=Preprocessing['patch_height_num'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cut 488nm channel\n",
    "cut.cut(root=Data_root, cut_size=Preprocessing['cut_size'], channel=Channels['autofluo'],\n",
    "cut_index_x=Preprocessing['cut_index_x'], cut_index_y=Preprocessing['cut_index_y'], \n",
    "patch_weight_num=Preprocessing['patch_weight_num'], patch_hegiht_num=Preprocessing['patch_height_num'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the size of the volume image is too large to be fed into the neural network, it is clipped into multiple subvolume images of size (64, 256, 256).\n",
    "* `cut_size` indicates the width and height of the clipped image.\n",
    "* `cut_index_x` denotes the x coordinate of the initial position of the clip.\n",
    "* `cut_index_y` denotes the y coordinate of the initial position of the clip.\n",
    "* `patch_weight_num` indicates that there are multiple patches in the width direction.\n",
    "* `patch_height_num` indicates that there are multiple patches in the height direction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[ImageJ](https://imagej.net/Fiji) shows clipped subvolume images of the 561 nm channel.\n",
    "\n",
    "![Clipping.png](..\\Docs\\Figure\\clipping.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spot segmentation\n",
    "Get the pixel-level labels of the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = Train_config['train_image_path']\n",
    "label_path = Train_config['train_label_path']\n",
    "sps.spot_seg(train_image_path=image_path, save_seg_path=label_path, channel=Channels['staining'], \n",
    "        scaling_param=Spot_seg_config['scaling_param'], wrapper_param=Spot_seg_config['wrapper_param'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rerference. Chen, J. et al. The Allen Cell and Structure Segmenter: a new open source toolkit for segmenting 3D intracellular structures in fluorescence microscopy images. \n",
    "\n",
    "[Article](http://biorxiv.org/lookup/doi/10.1101/491035).\n",
    "* `scaling_param` has two options: two values, say `[A, B]`, or single value, say `[K]`. For the first case, `A` and `B` are non-negative values indicating that the full intensity range of the stack will first be cut-off into **[mean - A * std, mean + B * std]** and then rescaled to **[0, 1]**. The smaller the values of `A` and `B` are, the higher the contrast will be. For the second case, `K`>0 indicates min-max Normalization with an absolute intensity upper bound `K` (i.e., anything above `K` will be chopped off and reset as the minimum intensity of the stack) and `K`=0 means min-max Normalization without any intensity bound.\n",
    "* `wrapper_param`: `[[scale_1, cutoff_1], [scale_2, cutoff_2], ....]` \n",
    "    * `scale_x` is set based on the estimated radius of your target dots. For example, if visually the diameter of the dots is usually 3~4 pixels, then you may want to set `scale_x` as `1` or something near `1` (like `1.25`). Multiple scales can be used, if you have dots of very different sizes.  \n",
    "    * `cutoff_x` is a threshold applied on the actual filter reponse to get the binary result. Smaller `cutoff_x` may yielf more dots and fatter segmentation, while larger `cutoff_x` could be less permisive and yield less dots and slimmer segmentation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [ImageJ](https://imagej.net/Fiji) display of spot segmentation result clipping.\n",
    "\n",
    "![spot_segmentation_clipped.png](..\\Docs\\Figure\\spot_seg_clip.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the training data.\n",
    "Images and labels make up the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join(Train_config['train_data_path'], 'train_data')\n",
    "tn.get_train_data(image_path, label_path, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the training data name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt.data_list(train_data=Network['train_data'], ratio=Network['train_valid_ratio'], test_id=Test_config['test_id'],\n",
    "        save_list=Network['save_data_list'], test_singel=Network['test_slice'], test_whole_brain=Network['test_whole_brain'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Parameters `train_data`, `test_single` and `test_whole_brain` correspond to three cases: training a neural network, testing a single brain slice and automatic whole-brain segmentation, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training neural networks\n",
    "\n",
    "![3D-HRFormer.png](..\\Docs\\Figure\\model.PNG)\n",
    "\n",
    "Importing Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Network.model.swin_transform import swin_tiny_patch4_window8_256\n",
    "# from Network.model.FCN_resnet3d import fcn_resnet34\n",
    "# from Network.model.unet3d import UNet3D\n",
    "# from Network.model.ASPP_unet3d import UNet3D\n",
    "# from Network.model.FCN import FCN\n",
    "from Network.utils import weights_init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whether to perform transfer learning or not, the default parameter is False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_train = Network['pre_train']\n",
    "checkpoint_path = os.path.join(pre_train, 'epoch_9.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else 'cpu')\n",
    "net = swin_tiny_patch4_window8_256(in_channels=Network['swin_in_channels'], num_classes=Network['num_classes']).to(device)\n",
    "# net = FCN(in_channels=1, num_classes=Network['num_classes']).to(device)\n",
    "# net = fcn_resnet34(num_classes=Network['num_classes']).to(device)\n",
    "# net = UNet3D(in_channel=1, n_classes=Network['num_classes']).to(device)\n",
    "# net = HRNet(num_classes=Network['num_classes']).to(device)\n",
    "net = net.apply(weights_init)\n",
    "print('net initialization succeeds !')\n",
    "train.train(net, checkpoint_path, pre_train, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Networks: **3D-HSFormer**, **FCN**, **ResNet34**, **UNet3D**, **HRNet**\n",
    "* `in_channels`: The input is a grayscale image and the default number of channels is 1.\n",
    "* `num_classes`: The input training labels are binarized images with a number of labels of 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_num = Preprocessing['patch_weight_num'] * Preprocessing['patch_height_num']\n",
    "ths.slice_test_data(image_patch_path=Test_config['test_image_path'], label_patch_path=Test_config['test_label_path'], \n",
    "                channel=Channels['staining'], save_test_path=Test_config['test_save_path'], patch_num=patch_num, \n",
    "                test_id=Test_config['test_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the performance of the network.\n",
    "Initialization parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Network.dataset_VISoR import VISoR_dataset\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--volume_path', type=str,\n",
    "                    default='', help='root dir for validation volume data') \n",
    "parser.add_argument('--dataset', type=str,\n",
    "                    default='VISoR', help='experiment_name')\n",
    "parser.add_argument('--max_epochs', type=int,\n",
    "                    default=Network['max_epochs'], help='maximum epoch number to train')\n",
    "parser.add_argument('--num_classes', type=int,\n",
    "                    default=Network['num_classes'], help='output channel of network')\n",
    "parser.add_argument('--list_dir', type=str,\n",
    "                    default='./lists', help='list dir')\n",
    "parser.add_argument('--model_name', type=str,\n",
    "                    default='swin', help='model_name')\n",
    "\n",
    "parser.add_argument('--batch_size', type=int, default=Network['test_batch_size'], help='batch_size per gpu')\n",
    "parser.add_argument('--img_size', type=int, default=Preprocessing['cut_size'], help='input patch size of network input')\n",
    "# parser.add_argument('--z_spacing', type=int, default=Network['z_spacing'], help='z spacing')\n",
    "parser.add_argument('--is_savetif', action=\"store_true\", default=True, help='whether to save results during inference')\n",
    "parser.add_argument('--test_id', type=int, default=30, help='test the 30th brain slice')\n",
    "parser.add_argument('--test_save_dir', type=str, default='../predictions', help='saving prediction as tif!')\n",
    "parser.add_argument('--base_lr', type=float,  default=Network['lr'], help='segmentation network learning rate')\n",
    "parser.add_argument('--patch_csv_root', type=str,  default=Network['save_patch_metrics'], help='The path to save the patch evaluation result csv')\n",
    "parser.add_argument('--slice_csv_root', type=str,  default=Network['save_metrics'], help='The path to save the slice evaluation result csv')\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "dataset_config = {\n",
    "    'VISoR': {\n",
    "        'Dataset': VISoR_dataset,\n",
    "        'volume_path': Test_config['test_save_path'],\n",
    "        'list_dir': '/home/weijie/3dHRNet/lists',\n",
    "        'num_classes': Network['num_classes'],\n",
    "        'z_spacing': Network['z_spacing'],\n",
    "    },\n",
    "}\n",
    "dataset_name = args.dataset\n",
    "args.exp = dataset_name + str(args.img_size)\n",
    "args.num_classes = dataset_config[dataset_name]['num_classes']\n",
    "args.volume_path = dataset_config[dataset_name]['volume_path']\n",
    "args.Dataset = dataset_config[dataset_name]['Dataset']\n",
    "args.list_dir = dataset_config[dataset_name]['list_dir']\n",
    "args.z_spacing = dataset_config[dataset_name]['z_spacing']\n",
    "args.test_id = Test_config['test_id']\n",
    "args.is_savetif = True\n",
    "\n",
    "# name the same snapshot defined in train script!\n",
    "snapshot_path = Network['snapshot_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net = HRNet(num_classes=args.num_classes, width=Model['hrnet_width']).cuda()\n",
    "# net = UNet3D(in_channel=Network['in_channels'], n_classes=args.num_classes).cuda()\n",
    "# net = FCN(in_channels=Network['in_channels'], num_classes=args.num_classes).cuda()\n",
    "# net = fcn_resnet34(num_classes=args.num_classes).cuda()\n",
    "net = swin_tiny_patch4_window8_256(in_channels=Network['swin_in_channels'], num_classes=args.num_classes).cuda()\n",
    "\n",
    "snapshot = os.path.join(snapshot_path, 'best_model.pth')\n",
    "if not os.path.exists(snapshot): snapshot = snapshot.replace('best_model', 'epoch_'+str(args.max_epochs-1))\n",
    "net.load_state_dict(torch.load(snapshot))\n",
    "snapshot_name = snapshot_path.split('/')[-1]\n",
    "\n",
    "log_folder = 'test_log/test_log_' + args.exp\n",
    "os.makedirs(log_folder, exist_ok=True)\n",
    "logging.basicConfig(filename=log_folder + '/'+snapshot_name+\".txt\", level=logging.INFO, format='[%(asctime)s.%(msecs)03d] %(message)s', datefmt='%H:%M:%S')\n",
    "logging.getLogger().addHandler(logging.StreamHandler(sys.stdout))\n",
    "logging.info(str(args))\n",
    "logging.info(snapshot_name)\n",
    "\n",
    "if args.is_savenii:\n",
    "    args.test_save_dir = os.path.join(Network['save_prediction_path'], 'brain_predications_' + args.test_id + '_' + args.model_name + '_epoch' + str(args.max_epochs))\n",
    "    test_save_path = os.path.join(args.test_save_dir, args.exp, snapshot_name)\n",
    "    os.makedirs(test_save_path, exist_ok=True)\n",
    "else:\n",
    "    test_save_path = None\n",
    "test.test(args, net, test_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segmentation evaluation\n",
    "|Evaluation metrics      |Description\n",
    "|:-----------------------|:--------------------------------------------------------------------------------------------------------------------------------\n",
    "|Dice coefficient        |The dice coefficient measures the similarity between the predicted segmentation map and the ground-true set of segmentation maps.\n",
    "|Jaccard coefficient     |The Jaccard coefficient is used to compare the similarities and differences between the predicted set and the ground-truth set.\n",
    "|Sensitivity             |The sensitivity describes the ratio of all true positives identified to all true positives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automated whole brain c-Fos expression for cellular segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Network.dataset_whole_brain import Whole_brain_dataset\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--volume_path', type=str,\n",
    "                    default='', help='root dir for validation volume data') \n",
    "parser.add_argument('--dataset', type=str,\n",
    "                    default='VISoR', help='experiment_name')\n",
    "parser.add_argument('--max_epochs', type=int,\n",
    "                    default=Network['max_epochs'], help='maximum epoch number to train')\n",
    "parser.add_argument('--num_classes', type=int,\n",
    "                    default=Network['num_classes'], help='output channel of network')\n",
    "parser.add_argument('--list_dir', type=str,\n",
    "                    default='./lists', help='list dir')\n",
    "parser.add_argument('--model_name', type=str,\n",
    "                    default='swin', help='model_name')\n",
    "\n",
    "parser.add_argument('--batch_size', type=int, default=Network['test_batch_size'], help='batch_size per gpu')\n",
    "parser.add_argument('--img_size', type=int, default=Preprocessing['cut_size'], help='input patch size of network input')\n",
    "parser.add_argument('--channel', type=str, default=Channels['staining'], help='inference channel')\n",
    "parser.add_argument('--is_savetif', action=\"store_true\", default=True, help='whether to save results during inference')\n",
    "parser.add_argument('--test_id', type=int, default=30, help='test the 30th brain slice')\n",
    "parser.add_argument('--test_save_dir', type=str, default='../predictions', help='saving prediction as tif!')\n",
    "parser.add_argument('--base_lr', type=float,  default=Network['lr'], help='segmentation network learning rate')\n",
    "parser.add_argument('--patch_csv_root', type=str,  default=Network['save_patch_metrics'], help='The path to save the patch evaluation result csv')\n",
    "parser.add_argument('--slice_csv_root', type=str,  default=Network['save_metrics'], help='The path to save the slice evaluation result csv')\n",
    "args = parser.parse_args(args=[])\n",
    "data_path = Infer['whole_brain_path']\n",
    "test_path = os.path.join(data_path, 'PatchImage_' + args.channel)\n",
    "for ind in range(1, len(os.listdir(test_path)) + 1):\n",
    "    dataset_config = {\n",
    "        'VISoR': {\n",
    "            'Dataset': Whole_brain_dataset,\n",
    "            'volume_path': test_path + '/patchimage{}'.format(ind),\n",
    "            'list_dir': Infer['whole_brain_list'],\n",
    "            'name_list': 'Z{:05d}_test'.format(ind),\n",
    "            'z_spacing': Network['z_spacing'],\n",
    "        },\n",
    "    }\n",
    "    dataset_name = args.dataset\n",
    "    args.exp = dataset_name + str(args.img_size)\n",
    "    args.volume_path = dataset_config[dataset_name]['volume_path']\n",
    "    args.Dataset = dataset_config[dataset_name]['Dataset']\n",
    "    args.list_dir = dataset_config[dataset_name]['list_dir']\n",
    "    args.name_list = dataset_config[dataset_name]['name_list']\n",
    "    args.z_spacing = dataset_config[dataset_name]['z_spacing']\n",
    "    \n",
    "    # name the same snapshot defined in train script!\n",
    "    snapshot_path = Infer['snapshot_path']\n",
    "    net = swin_tiny_patch4_window8_256(in_channels=Infer['swin_in_channels'], num_classes=args.num_classes).cuda()\n",
    "\n",
    "    snapshot = os.path.join(snapshot_path, 'best_model.pth')\n",
    "    if not os.path.exists(snapshot): snapshot = snapshot.replace('best_model', 'epoch_'+str(args.max_epochs-1))\n",
    "    net.load_state_dict(torch.load(snapshot))\n",
    "    snapshot_name = snapshot_path.split('/')[-1]\n",
    "\n",
    "    log_folder = 'test_log/test_log_' + args.exp\n",
    "    os.makedirs(log_folder, exist_ok=True)\n",
    "    logging.basicConfig(filename=log_folder + '/'+snapshot_name+\".txt\", level=logging.INFO, format='[%(asctime)s.%(msecs)03d] %(message)s', datefmt='%H:%M:%S')\n",
    "    logging.getLogger().addHandler(logging.StreamHandler(sys.stdout))\n",
    "    logging.info(str(args))\n",
    "    logging.info(snapshot_name)\n",
    "\n",
    "    if args.is_savetif:\n",
    "        args.test_save_dir = data_path + '/whole_predications_' + args.channel + '/brain_predications_{}_swin_epoch10'.format(ind)\n",
    "        test_save_path = os.path.join(args.test_save_dir, args.exp, snapshot_name)\n",
    "        os.makedirs(test_save_path, exist_ok=True)\n",
    "    else:\n",
    "        test_save_path = None\n",
    "    infer_whole.infer_whole_brain(args, net, ind, test_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splice\n",
    "Automatic segmentation of volume image decomposition into 2-dimensional images.\n",
    "\n",
    "The segmentation result (z, x, y) is stitched into a volume image of size (64, 3500, 2500)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel = Channels['staining']\n",
    "pred_root = os.path.join(Data_root, 'whole_predications_' + channel)\n",
    "path = os.path.join(Data_root, 'brain_image_64_' + channel)\n",
    "save_path_3d = os.path.join(Splicing['save_splicing_path'], 'whole_brain_pred_' + channel)\n",
    "os.makedirs(save_path_3d, exist_ok=True)\n",
    "infer_total_num = len(os.listdir(path))\n",
    "resuidual_z = total_num - (Preprocessing['z_num'] * infer_total_num)\n",
    "patch_total_num = Preprocessing['patch_weight_num'] * Preprocessing['patch_height_num']\n",
    "for num in range(1, len(os.listdir(path)) + 1):\n",
    "    list = rt.load(path, num, total_patch_num=patch_total_num)\n",
    "    rt.concat(list, save_path_3d, num)\n",
    "    print('finished {} image '.format(num))\n",
    "rt.create_residual_image(save_path_3d, infer_total_num + 1, resuidual_z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-processing\n",
    "Post-processing of the predicted segmentation results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = os.path.join(Data_root, 'brain_image_64_' + Channels['staining'])\n",
    "path = Splicing['save_splicing_path']\n",
    "pred_path = os.path.join(path, 'whole_brain_pred_' + Channels['staining'])\n",
    "path_488nm = os.path.join(path, 'whole_brain_pred_' + Channels['autofluo'])\n",
    "save_path = os.path.join(path, 'whole_brain_pred_post_filter')\n",
    "post.spot_filter(image_path, pred_path, path_488nm, save_path, lower_limit=Post['intensity_lower_differ'], \n",
    "                    upper_limit=Post['intensity_upper_differ'], min_size=Post['point_min_size'], max_intensity=Post['big_object_size'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The post-processing process is divided into three main steps:\n",
    "\n",
    "1. **Autofluorescence filter** is utilized for its predictive segmentation to clear the segmentation of the network predicted autofluorescence signal in the c-Fos channel.\n",
    "2. **No-soma filter** can remove unreasonably small or large objects from the network prediction segmentation results.\n",
    "3. **Intensity based prediction result filter** is to remove predicted segmentations with weak c-Fos+ signal intensity (intensity values close to the brain parenchyma signal intensity).\n",
    "* `lower_limit`  is the lower bound of the difference between the weak signal and the segmentation mask (Mask value = 255).\n",
    "* `upper_limit`  is the upper bound of the difference between the weak signal and the segmentation mask (Mask value = 255).\n",
    "* `min_size` is the minimum value of cell size.\n",
    "* `max_intensity` is the maximum value of the segmented object signal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both labeled signal channels and autofluorescent channels underwent the above steps to obtain c-Fos+ segmentation of the whole brain.\n",
    "\n",
    "Below is an image of [Imaris](http://www.bitplane.com/imaris/imaris) showing the three channels.\n",
    "\n",
    "![whole_segmentation.png](../Docs/Figure/whole_seg.PNG)\n",
    "\n",
    "`Red channel`: c-Fos+, `Green channel`: autofluorescent, `Bule channel`: segmentation mask."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Registration\n",
    "Reconstructed image voxels (4x4x4 μm) resampled voxels are (25x25x25 μm). \n",
    "\n",
    "The reconstructed brain was registered with a reference [autofluorescent brain](http://www.idisco.info) using [Elastix](http://elastix.isi.uu.nl). Transformation parameters of brain alignment were used to obtain the location of cells in the whole brain.\n",
    "\n",
    "Register to [Allen Brain Atlas CCFv3]((http://atlas.brain-map.org/))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruction_root = os.path.join(Registration['Raw_brain_path'], 'Reconstruction')\n",
    "image_list_file = os.path.join(reconstruction_root, 'BrainImage', 'freesia_4.0_C2_488nm_10X.json')\n",
    "output_path = Registration['output_path'] \n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "template_file = 'Registration/data/ccf_v3_template.json'\n",
    "output_name = Registration['output_name']\n",
    "transform_path = os.path.join(reconstruction_root, 'BrainTransform', 'visor_brain.txt')\n",
    "br.register_brain(image_list_file=image_list_file, output_path=output_path, template_file=template_file, output_name=output_name, \n",
    "                brain_transform_path=transform_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use [freesia](https://github.com/BilabOptics/freesia-mapping) to open the **Thumbnail_25.0.json** file generated by the registration program.\n",
    "\n",
    "![step1.png](../Docs/Figure/freesia_step1.png)\n",
    "\n",
    "![step2.png](../Docs/Figure/freesia_step2.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sopt mapping\n",
    "\n",
    "The results of the segmentation were composed into brain slices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tempfile.TemporaryDirectory() as TEMP_PATH:\n",
    "    splice_path = Splicing['save_splicing_path']\n",
    "    data_path = os.path.join(splice_path, 'whole_brain_pred_post_filter')\n",
    "    save_path = os.path.join(TEMP_PATH, 'whole_brain_pred_2d')\n",
    "    s3t2.seg3d_to_2d(data_path, save_path)\n",
    "    save_root = os.path.join(splice_path, 'whole_brain_pred_3d')\n",
    "    st.BrainImage_cat(save_path, save_root, flip=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The coordinates of the center of mass of each cell were counted. \n",
    "\n",
    "For each c-Fos+ object, the coordinate  values of the three directions of the centroid coordinates 4 × (x, y, z)  were obtained as its physical coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BrainImage_root = os.path.join(path, 'whole_brain_pred_3d')\n",
    "csv_root = os.path.join(path, 'whole_brain_cell_counts')\n",
    "st.BrainImage2Spot(BrainImage_root, csv_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Segmentation of cells mapped to the Allen Brain Atlas. (Coronal plane)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_csv_root = os.path.join(csv_root, 'Thumbnail_CSV')\n",
    "total_path = os.path.join(save_csv_root, 'total.txt')\n",
    "st.Spot_csv(total_path, csv_root, brainimage2d_num=total_num, group_num=Spot_map['group_num'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`group_num` is the number of `brainimage2d_num` divided by the number of thumbnails (thumbnails are obtained after alignment)\n",
    "\n",
    "`group_num` = 25 μm / 4 μm = 6.25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Segmentation of cells mapped to the Allen Brain Atlas. (Sagittal plane)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.Sagittal_spot_csv(total_path, csv_root, brainimage_x=Brain['weight'], group_num=Spot_map['group_num'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`brainimage_x` is the width of the reconstructed brain image, the default is 3500."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Segmentation of cells mapped to the Allen Brain Atlas. (Horizontal plane)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.Horizontal_spot_csv(total_path, csv_root, brainimage_y=Brain['height'], group_num=Spot_map['group_num'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`brainimage_y` is the height of the reconstructed brain image, the default is 2500.\n",
    "\n",
    "The coordinates of the cell mapping positions in the horizontal and sagittal planes at 25 μm can be used to generate horizontal and sagittal cell heat maps for the analysis process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The location coordinates of the mapped cells were imported using [freesia](https://github.com/BilabOptics/freesia-mapping) to complete cell counts in different brain regions.\n",
    "\n",
    "1. Import **Spot mapping** to generate **Thumbnail_CSV** folder.\n",
    "\n",
    "![step3.png](../Docs/Figure/freesia_step3.png)\n",
    "\n",
    "![out.png](../Docs/Figure/freesia_output1.png)\n",
    "\n",
    "2. Export cell counting result.\n",
    "\n",
    "![step4.png](../Docs/Figure/freesia_step4.png)\n",
    "\n",
    "3. Merger cell counting result.\n",
    "\n",
    "![step5.png](../Docs/Figure/freesia_step5.png)\n",
    "\n",
    "Output the **cell-counting.csv** file containing the count results for each brain region."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "Remove the cell center-of-mass coordinate points from the freesia-derived image to obtain atlas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## freesia export cell counts\n",
    "image_root = os.path.join(freesia_export_path, 'images')\n",
    "fb.regenAtlas(image_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain the boundaries of the brain atlas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas_root = os.path.join(image_root, '..', 'atlas')\n",
    "Edge_root = os.path.join(image_root, '..', 'Edge')\n",
    "fb.genEdgefromAtlas(atlas_root, Edge_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain a brain atlas of the segmented to cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Points_root = os.path.join(image_root, '..', 'Points')\n",
    "fb.genPoints(image_root,Points_root)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain segmentation masks and cellular distribution of brain regions of interest.\n",
    "* `Mask_id` is the pixel value of the brain region annotation.\n",
    "\n",
    "More pixel values for brain area annotations can be found in the **Parameter.py** file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Region_name = 'CBX'\n",
    "Mask_id = Whole_brain_region_level2[Region_name]#CBX\n",
    "Region_root = os.path.join(image_root, '..', 'Region')\n",
    "Points_SingleRegion_root = os.path.join(image_root, '..', 'Points_Single_Region')\n",
    "fb.genSingleRegion(atlas_root, Region_root, Region_name, Mask_id)\n",
    "fb.genPointsSingleRegion(image_root, Region_root, Points_SingleRegion_root, Region_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the surface and spot functions in [Imaris](http://www.bitplane.com/imaris/imaris) to demonstrates the distribution of selected brain regions and c-Fos-expressing cells.\n",
    "\n",
    "![Region.png](../Docs/Figure/Region_spot.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code inputs the parameter `Whole_brain_reigon_level2` and renders the brain region annotations in combination with the surface function of [Imaris](http://www.bitplane.com/imaris/imaris).\n",
    "\n",
    "![whole_brain_anno.png](../Docs/Figure/whole_brain_anno.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acquisition of a whole brain cell activity map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join(Points_root, '..', '3d_result')\n",
    "save_name = 'whole_brain_point'\n",
    "altas_num = Preprocessing['brain_total_num'] / Spot_map['group_num']\n",
    "fb.concat_image(Points_root, save_path, z_num=altas_num, save_name=save_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the whole brain cell activity map.\n",
    "* `Atlas_snapshot_id` is the index corresponding to atlas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Save_root = Atlas_edge_pionts_save_path\n",
    "fb.genMergeRaw(Edge_root, Points_root, Save_root, Atlas_snapshot_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of cells in each layer in different regions of the cerebral cortex was obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Data_root\n",
    "data_name = Stats['group_data_name']\n",
    "for k in range(len(data_name)):\n",
    "    csv_path = os.path.join(root, data_name[k], 'whole_brain_cell_counts')\n",
    "    ct.cortex_stats(csv_path)\n",
    "    print('finished {}'.format(data_name[k]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Access to different areas of the cerebral cortex and c-Fos-expressing cells.\n",
    "* `get_point`: When False, the generation is a brain area mask. When True, the production is a c-Fos-expressing cell mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Data_root\n",
    "data_name = Stats['Pred_data_list']\n",
    "for i in range(len(data_name)):\n",
    "    image_root = os.path.join(root, data_name[i], 'whole_brain_cell_counts/images')\n",
    "    altas_root =  os.path.join(image_root, '..', 'atlas')\n",
    "    save_region_root = os.path.join(image_root, '..', 'cortex_region')\n",
    "    save_points_region_root = os.path.join(image_root, '..', 'points_cortex_region')\n",
    "    rl.get_multi_region(Isocortex, image_root, altas_root, save_region_root, save_points_region_root, get_point=True)\n",
    "\n",
    "    save_layer_root = os.path.join(image_root, '..', 'cortex_layer')\n",
    "    save_points_layer_root = os.path.join(image_root, '..', 'points_cortex_layer')\n",
    "    rl.get_multi_layer(Isocortex, image_root, altas_root, save_layer_root, save_points_layer_root, get_point=True)\n",
    "    print('finished {}'.format(data_name[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The spot function of [Imaris](http://www.bitplane.com/imaris/imaris) displays the cellular distribution of c-Fos expression each layer.\n",
    "\n",
    "![ssp_layer.png](../Docs/Figure/ssp_layer.png)\n",
    "\n",
    "<font color=\"#dd0000\">**SSp layer 1** </font><br />\n",
    "<font color=\"#00dd00\">**SSp layer 2/3** </font><br />\n",
    "<font color=\"#FB04EA\">**SSp layer 4** </font><br />\n",
    "<font color=\"#1B8BE4\">**SSp layer 5** </font><br />\n",
    "<font color=\"#8D03FC\">**SSp layer 6** </font><br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Volume ratio\n",
    "Calculated region and cell volume ratio in each layer.\n",
    "\n",
    "The **volume ratio** computed as (total c-Fos+ neurons volume in the region / region volume) * 100%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Data_root\n",
    "data_name = Stats['group_data_name']\n",
    "\n",
    "for ind in range(len(data_name)):\n",
    "    region_path = os.path.join(root, data_name[ind], 'whole_brain_cell_counts', 'cortex_region')\n",
    "    points_label_path = os.path.join(root, data_name[ind], 'whole_brain_cell_counts', 'points_cortex_region')\n",
    "    save_volume_ratio = os.path.join(region_path, '..')\n",
    "    vr.get_volume_ratio_csv(Isocortex, region_path, points_label_path, save_volume_ratio)\n",
    "    print('finished {}'.format(data_name[ind]))\n",
    "\n",
    "for ind in range(0, len(data_name)):\n",
    "    path = os.path.join(root, data_name[ind], 'whole_brain_cell_counts')\n",
    "    layer_path = os.path.join(path, 'cortex_layer')\n",
    "    layer_points_path = os.path.join(path, 'points_cortex_layer')\n",
    "    vr.get_whole_layer_volume(Isocortex, layer_path, layer_points_path, savecsv=path)\n",
    "    print('finished {}'.format(data_name[ind]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the mean value of the cell volume ratio in the area and in each layer of the experimental or control group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctrl_name = Stats['Ctrl_data_list']\n",
    "fs_name = Stats['FST_data_list']\n",
    "vr.get_whole_layer_mean_volume(root, ctrl_name, Isocortex, save_csv=root, group_name='Ctrl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Density\n",
    "Calculated region and cell density in each layer\n",
    "\n",
    "The **density** is quantified number of individual c-Fos+ neurou per volume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Data_root\n",
    "fs_name = Stats['FST_data_list']\n",
    "ctrl_name = Stats['Ctrl_data_list']  \n",
    "data_name = Stats['Pred_data_list']\n",
    "\n",
    "for ind in range(len(data_name)):\n",
    "    region_path = os.path.join(root, data_name[ind], 'whole_brain_cell_counts', 'cortex_region')\n",
    "    csv_path = os.path.join(root, data_name[ind])\n",
    "    save_density = os.path.join(region_path, '..')\n",
    "    ds.get_density_csv(region_path, csv_path, Isocortex, save_density)\n",
    "    print('finished {}'.format(data_name[ind]))\n",
    "\n",
    "for ind in range(len(data_name)):\n",
    "    path = os.path.join(root, data_name[ind], 'whole_brain_cell_counts')\n",
    "    layer_path = os.path.join(path, 'cortex_layer')\n",
    "    layer_points_path = os.path.join(path, 'points_cortex_layer')\n",
    "    ds.get_whole_layer_density(Isocortex, root, layer_path, data_name[ind], path)\n",
    "    print('finished {}'.format(data_name[ind]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Calculate the mean value of the cell density in the area and in each layer of the experimental or control group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.get_whole_layer_mean_density(root, fs_name, Isocortex, save_csv=root, group_name='FS') # group_name = 'FS' or 'Ctrl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intensity\n",
    "\n",
    "Calculate the intensity values of cell signals in different regions.\n",
    "\n",
    "* `id` is the serial number of the experimental group or the control group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Data_root\n",
    "data_path = os.path.join(root, 'Brainimage_25mic')\n",
    "label_path = os.path.join(root, '', r'whole_brain_cell_counts\\points_cortex_region')\n",
    "save_csv_root = os.path.join(root, '', r'whole_brain_cell_counts\\cortex_intensity')\n",
    "it.get_intensity_csv(Isocortex, data_path, label_path, save_csv_root, id='Ctrl10')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The percentage of intensity values of cell signals in different regions was calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intensity_root = os.path.join(Data_root, '', r'whole_brain_cell_counts\\cortex_intensity')\n",
    "savepath = os.path.join(intensity_root, '..', 'intensity_normalized_counts')\n",
    "it.normalized_counts(Isocortex, intensity_root, savepath)\n",
    "it.get_whole_norm_counts(path=savepath, region_color=Isocortex, csv_name='Norm_counts.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The intensity values of the cell signals in each subvolume were calculated.\n",
    "* `min_volume` indicates the signal intensity of the minimum volume of statistical cells.\n",
    "* `max_volume` indicates the signal intensity of the maximum volume of statistical cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_path = ''\n",
    "it.patch_intensity(data_path=patch_path, label_path=patch_path, save_csv_root=patch_path, min_volume=Stats['min_volume'], max_volume=Stats['max_volume'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics\n",
    "Statistical hypothesis testing of metrics for evaluating DNN segmentation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat.DNN_result_ranksum(data_path=Stats['DNN_results'], model_name=Stats['Model_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell count results derived from [freesia](https://github.com/BilabOptics/freesia-mapping) are selected for a particular level of brain area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Data_root\n",
    "data_name = Stats['Pred_data_list']\n",
    "for i in range(0, len(data_name)):\n",
    "    csv_path = os.path.join(root, data_name[i], 'whole_brain_cell_counts/cell-counting.csv')\n",
    "    save_path = os.path.join(root, data_name[i], 'whole_brain_cell_counts')\n",
    "    stat.select_level(csv_path, save_path)\n",
    "    print('finished {}'.format(data_name[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The total number of cells in different brain regions or the total number of cells in the left and right parts of different regions were exported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data_name)):\n",
    "    csv_path = os.path.join(root, data_name[i], 'whole_brain_cell_counts/cell-counts-level6.csv')\n",
    "    save_path = os.path.join(root, data_name[i], 'whole_brain_cell_counts')\n",
    "    stat.level6_sum(csv_path, save_path)\n",
    "    stat.level6_left_right_brain(csv_path, save_path)\n",
    "    print('finished {}'.format(data_name[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistical hypotheses were tested for the number of cells in different brain regions or the number of cells in the left and right parts of different regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_name = Stats['FST_data_list']\n",
    "ctrl_name = Stats['Ctrl_data_list']\n",
    "stat.ttest_level6(root, fs_name, ctrl_name)\n",
    "stat.ttest_level6_left_right(root, fs_name, ctrl_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exported statistical hypothesis test signs for the number of cells in the left and right brain halves.\n",
    "* `select_left`: False -> Statistics right brain\n",
    "* `select_left`: True -> Statistics left brain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat.symbol_left_right_ci(csv_path=root, save_csv=root, select_left=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistical hypothesis tests were performed on the volume ratio of left and right brain cell halves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat.ttest_multi_region_vol(root, fs_name, ctrl_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results were derived for the number of cells in brain regions at different significant levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol = Stats['symbol']\n",
    "pvals_cutoff = Stats['pvals_cutoff']\n",
    "for i in range(len(data_name)):\n",
    "    save_path = os.path.join(root, data_name[i], 'whole_brain_cell_counts/csv')\n",
    "    os.makedirs(save_path,exist_ok=True) \n",
    "    stat.get_multi_cl_counts(root, data_name[i], save_path, symbol, pvals_cutoff)\n",
    "    print('finished {}'.format(data_name[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistical hypothesis testing was performed on the results for different regions of the cerebral cortex and the number of cells each layer.\n",
    "\n",
    "Results were derived for the number of cells in each layer at different significant levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_name = Stats['layer_name']\n",
    "save_layer_name = Stats['save_layer_name']\n",
    "stats_dtype = Stats['stats_dtype']\n",
    "for ln in range(len(layer_name)):\n",
    "    stat.ttest_multi_layer(root, fs_name, ctrl_name, layer_name[ln], save_layer_name[ln], stats_dtype[2])\n",
    "    stat.get_layer_ci(root, layer_name[ln], save_layer_name[ln], save_csv=root)\n",
    "    print(layer_name[ln])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demonstrate the number of cells in the brain region of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_region_name = Stats['display_region_name']\n",
    "for i in range(len(data_name)):\n",
    "    save_path = os.path.join(root, data_name[i], 'whole_brain_cell_counts/csv')\n",
    "    os.makedirs(save_path,exist_ok=True) \n",
    "    stat.get_plot_region_counts(root, data_name[i], plot_region_name, save_path, pvals_cutoff)\n",
    "    print('finished {}'.format(data_name[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of cells in statistical level 2 brain regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat.level2_count(csv_path=Data_root, save_csv=Data_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heat map\n",
    "Heat map of cellular activity in the coronal, horizontal and sagittal planes.\n",
    "* `fname` is a certain atlas id.csv file in the **Thumbnail_CSV** folder of the experimental and control groups, which records the center-of-mass coordinates of the cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Data_root\n",
    "fname = {'FS8':'0490_25', 'Ctrl8':'0490_25'}\n",
    "z_length = Preprocessing['brain_total_num'] / Spot_map['group_num']\n",
    "data_name = [ '', '', ...]\n",
    "group_name = list(fname.keys())\n",
    "for i in range(len(data_name)):\n",
    "    data_path = os.path.join(root, data_name[i], 'coordinate')\n",
    "    save_path = os.path.join(root, data_name[i], 'cell_density')\n",
    "    pv.cell_heatmap(data_path, save_path, fname=fname[group_name[i]])\n",
    "    pv.sagittal_cell_heatmap(data_path, save_path, fname[group_name[i]], z_length)\n",
    "    pv.horizontal_cell_heatmap(data_path, save_path, fname[group_name[i]], z_length)\n",
    "    print('finished {}'.format(group_name[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[ImageJ](https://imagej.net/Fiji) displays the cellular thermogram of the coronal plane.\n",
    "\n",
    "**Left**: forced swimming test group. **Right**: Control group\n",
    "\n",
    "![heatmap.png](../Docs/Figure/heatmap.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the cell density mapped at 25 microns\n",
    "\n",
    "A total of `35` snapshots were taken, each with an interval atlas id of `16`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data_name)):\n",
    "    for j in range(35):\n",
    "        index = j*16\n",
    "        pv.group_cell_heatmap(data_path=os.path.join(root, data_name[i]), save_path=os.path.join(root, data_name[i], 'group_cell_denisty'), id=index)\n",
    "        if index >= z_length:\n",
    "            break\n",
    "        print('finish {}'.format(index))\n",
    "        print('finished' + data_name[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whole brain cell heat map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = os.path.join(Data_root, '', r'whole_brain_cell_counts\\Thumbnail_CSV')\n",
    "save_path = os.path.join(Data_root, '', 'cell_density')\n",
    "save_name = ''\n",
    "pv.whole_brain_cell_heatmap(csv_path, save_path, z_length=len(os.listdir(csv_path)), save_name=save_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P-value map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group1 = ['', '', ...]\n",
    "group2 = ['', '', ...]\n",
    "fs_name = Stats['FST_data_list']\n",
    "ctrl_name = Stats['Ctrl_data_list']\n",
    "for i in range(35):\n",
    "    index = i*16\n",
    "    group_fs = [os.path.join(root, fs_name[j], 'group_cell_denisty\\{}_cell_density.tif'.format(index)) for j in range(len(fs_name))]\n",
    "    # group1.append(group_fs)\n",
    "    group_ctrl = [os.path.join(root, ctrl_name[k], 'group_cell_denisty\\{}_cell_density.tif'.format(index)) for k in range(len(ctrl_name))]\n",
    "    # group2.append(group_ctrl)\n",
    "    save_p_map_path = os.path.join(Data_root, '', 'group_p_map')\n",
    "    save_name = str(index) + '_p_map' \n",
    "    pv.generate_p_mapping(group_fs, group_ctrl, save_p_map_path, save_name)\n",
    "    print('finished {}'.format(index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [ImageJ](https://imagej.net/Fiji) display generates a P-value map.\n",
    "\n",
    "The **light blue area** indicates a significant difference in the number of regional c-Fos+ cells between the FST group and the control group.\n",
    "\n",
    "![p_vaule.png](../Docs/Figure/P_value.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the coefficient of variation (CV) and z-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = Stats['level6_cell_counts_path']\n",
    "index = Stats['group_index']\n",
    "cz.coefficient_of_variation(csv_path=csv_path, save_path=csv_path, index=index)\n",
    "cz.z_score(csv_path=csv_path, save_path=csv_path, index=index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the log2(fold change)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Data_root\n",
    "exp_name = Stats['Exp_data_list'] \n",
    "obser_name = Stats['Observe_data_list'] \n",
    "con_name = Stats['Ctrl_data_list']\n",
    "lc.log2Change(root, exp_name, obser_name, con_name) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the spearman's correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = Data_root\n",
    "save_root = Data_root\n",
    "sc.spearman_corr(data_root, save_root)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8349e950bccd14454d54d4e17739ac3ee8a5a1d494e2abca4fc6c8a9ff25d9f2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('sitkpy': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
